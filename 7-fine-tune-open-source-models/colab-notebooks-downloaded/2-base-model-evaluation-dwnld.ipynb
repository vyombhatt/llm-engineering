{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHsssBgWM_l0"
      },
      "source": [
        "## Predict Product Prices\n",
        "\n",
        "### Week 7 Day 2\n",
        "\n",
        "Selecting our model and evaluating the base model against the task.\n",
        "\n",
        "Keep in mind: our base model has 8 billion params, quantized down to 4 bits\n",
        "Compared with GPT-4o at TRILLIONS of params!\n",
        "\n",
        "# IMPORTANT please read me!!\n",
        "\n",
        "When you run the pip installs below, you may get an error from pip complaining about an incompatible version of fsspec.\n",
        "\n",
        "You should ignore that error! The version of fsspec is the right version, needed by HuggingFace.\n",
        "\n",
        "If you ask ChatGPT, it will encourage you to pip install a more recent version of fsspec. But that would be problematic; HuggingFace will fail to load the dataset later with an obscure error about file systems.\n",
        "\n",
        "So please run the pip installs as they appear below, and look the other way if you get an error!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDyR63OTNUJ6"
      },
      "outputs": [],
      "source": [
        "# pip installs - ignore the error message!\n",
        "\n",
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q --upgrade requests==2.32.3 bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 datasets==3.2.0 peft==0.14.0 trl==0.14.0 matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yikV8pRBer9"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, set_seed\n",
        "from peft import LoraConfig, PeftModel\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuTX-xonNeOK"
      },
      "outputs": [],
      "source": [
        "# Tokenizers\n",
        "\n",
        "LLAMA_3_1 = \"meta-llama/Meta-Llama-3.1-8B\"\n",
        "QWEN_2_5 = \"Qwen/Qwen2.5-7B\"\n",
        "GEMMA_2 = \"google/gemma-2-9b\"\n",
        "PHI_3 = \"microsoft/Phi-3-medium-4k-instruct\"\n",
        "\n",
        "# Constants\n",
        "\n",
        "BASE_MODEL = LLAMA_3_1\n",
        "HF_USER = \"ed-donner\"\n",
        "DATASET_NAME = f\"{HF_USER}/pricer-data\"\n",
        "MAX_SEQUENCE_LENGTH = 182\n",
        "QUANT_4_BIT = True\n",
        "\n",
        "# Used for writing to output in color\n",
        "\n",
        "GREEN = \"\\033[92m\"\n",
        "YELLOW = \"\\033[93m\"\n",
        "RED = \"\\033[91m\"\n",
        "RESET = \"\\033[0m\"\n",
        "COLOR_MAP = {\"red\":RED, \"orange\": YELLOW, \"green\": GREEN}\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JArT3QAQAjx"
      },
      "source": [
        "### Log in to HuggingFace\n",
        "\n",
        "If you don't already have a HuggingFace account, visit https://huggingface.co to sign up and create a token.\n",
        "\n",
        "Then select the Secrets for this Notebook by clicking on the key icon in the left, and add a new secret called `HF_TOKEN` with the value as your token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyFPZeMcM88v"
      },
      "outputs": [],
      "source": [
        "# Log in to HuggingFace\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def investigate_tokenizer(model_name):\n",
        "  print(\"Investigating tokenizer for\", model_name)\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "  for number in [0, 1, 10, 100, 999, 1000]:\n",
        "    tokens = tokenizer.encode(str(number), add_special_tokens=False)\n",
        "    print(f\"The tokens for {number}: {tokens}\")"
      ],
      "metadata": {
        "id": "3ttdsrJkMsTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will try this with each model: LLAMA_3_1, QWEN_2_5, GEMMA_2, PHI_3\n",
        "\n",
        "investigate_tokenizer(PHI_3)"
      ],
      "metadata": {
        "id": "CqwfO4zzNrLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load our data\n",
        "\n",
        "We uploaded it to Hugging Face, so it's easy to retrieve it now"
      ],
      "metadata": {
        "id": "DTMo_1msQb9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(DATASET_NAME)\n",
        "train = dataset['train']\n",
        "test = dataset['test']"
      ],
      "metadata": {
        "id": "5PVXACKHQhh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[0]"
      ],
      "metadata": {
        "id": "pGJR24lbQlRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare our Base Llama Model for evaluation\n",
        "\n",
        "Load our base model with 4 bit quantization and try out 1 example"
      ],
      "metadata": {
        "id": "vrxH6h00P9qc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_O04fKxMMT-"
      },
      "outputs": [],
      "source": [
        "## pick the right quantization\n",
        "\n",
        "if QUANT_4_BIT:\n",
        "  quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        "  )\n",
        "else:\n",
        "  quant_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_compute_dtype=torch.bfloat16\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Tokenizer and the Model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "base_model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "print(f\"Memory footprint: {base_model.get_memory_footprint() / 1e9:.1f} GB\")"
      ],
      "metadata": {
        "id": "TAit9IzsQLcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_price(s):\n",
        "    if \"Price is $\" in s:\n",
        "      contents = s.split(\"Price is $\")[1]\n",
        "      contents = contents.replace(',','').replace('$','')\n",
        "      match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", contents)\n",
        "      return float(match.group()) if match else 0\n",
        "    return 0"
      ],
      "metadata": {
        "id": "1FfMJ2JbzEr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_price(\"Price is $999 blah blah so cheap\")"
      ],
      "metadata": {
        "id": "jRpAKygTgAoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_predict(prompt):\n",
        "    set_seed(42)\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    attention_mask = torch.ones(inputs.shape, device=\"cuda\")\n",
        "    outputs = base_model.generate(inputs, max_new_tokens=4, attention_mask=attention_mask, num_return_sequences=1)\n",
        "    response = tokenizer.decode(outputs[0])\n",
        "    return extract_price(response)"
      ],
      "metadata": {
        "id": "CgN8eRttRAZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict(test[0]['text'])"
      ],
      "metadata": {
        "id": "hpdEk2-FW6aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation!\n",
        "\n",
        "Trying out our base Llama 3.1 model against the Test dataset"
      ],
      "metadata": {
        "id": "auFzPUJKTLln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tester:\n",
        "\n",
        "    def __init__(self, predictor, data, title=None, size=250):\n",
        "        self.predictor = predictor\n",
        "        self.data = data\n",
        "        self.title = title or predictor.__name__.replace(\"_\", \" \").title()\n",
        "        self.size = size\n",
        "        self.guesses = []\n",
        "        self.truths = []\n",
        "        self.errors = []\n",
        "        self.sles = []\n",
        "        self.colors = []\n",
        "\n",
        "    def color_for(self, error, truth):\n",
        "        if error<40 or error/truth < 0.2:\n",
        "            return \"green\"\n",
        "        elif error<80 or error/truth < 0.4:\n",
        "            return \"orange\"\n",
        "        else:\n",
        "            return \"red\"\n",
        "\n",
        "    def run_datapoint(self, i):\n",
        "        datapoint = self.data[i]\n",
        "        guess = self.predictor(datapoint[\"text\"])\n",
        "        truth = datapoint[\"price\"]\n",
        "        error = abs(guess - truth)\n",
        "        log_error = math.log(truth+1) - math.log(guess+1)\n",
        "        sle = log_error ** 2\n",
        "        color = self.color_for(error, truth)\n",
        "        title = datapoint[\"text\"].split(\"\\n\\n\")[1][:20] + \"...\"\n",
        "        self.guesses.append(guess)\n",
        "        self.truths.append(truth)\n",
        "        self.errors.append(error)\n",
        "        self.sles.append(sle)\n",
        "        self.colors.append(color)\n",
        "        print(f\"{COLOR_MAP[color]}{i+1}: Guess: ${guess:,.2f} Truth: ${truth:,.2f} Error: ${error:,.2f} SLE: {sle:,.2f} Item: {title}{RESET}\")\n",
        "\n",
        "    def chart(self, title):\n",
        "        max_error = max(self.errors)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        max_val = max(max(self.truths), max(self.guesses))\n",
        "        plt.plot([0, max_val], [0, max_val], color='deepskyblue', lw=2, alpha=0.6)\n",
        "        plt.scatter(self.truths, self.guesses, s=3, c=self.colors)\n",
        "        plt.xlabel('Ground Truth')\n",
        "        plt.ylabel('Model Estimate')\n",
        "        plt.xlim(0, max_val)\n",
        "        plt.ylim(0, max_val)\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "\n",
        "    def report(self):\n",
        "        average_error = sum(self.errors) / self.size\n",
        "        rmsle = math.sqrt(sum(self.sles) / self.size)\n",
        "        hits = sum(1 for color in self.colors if color==\"green\")\n",
        "        title = f\"{self.title} Error=${average_error:,.2f} RMSLE={rmsle:,.2f} Hits={hits/self.size*100:.1f}%\"\n",
        "        self.chart(title)\n",
        "\n",
        "    def run(self):\n",
        "        self.error = 0\n",
        "        for i in range(self.size):\n",
        "            self.run_datapoint(i)\n",
        "        self.report()\n",
        "\n",
        "    @classmethod\n",
        "    def test(cls, function, data):\n",
        "        cls(function, data).run()"
      ],
      "metadata": {
        "id": "jnoI1EWGTUau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tester.test(model_predict, test)"
      ],
      "metadata": {
        "id": "1wA5uVgpTWLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5qgNxGCmNAw2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}